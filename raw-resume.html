---
layout: default
title: Raw Resume
---

<div id="raw-resume-content">
    <div>
        <h2 class="children-center">{{site.name}}</h2>
    </div>
    <div>
        <div class="children-center">
            <div class="inline-block">{{site.phone}}</div> |
            <div class="inline-block"><a>{{site.email}}</a></div> |
            <div class="inline-block">{{site.location}}</div> |
            <div class="inline-block"><a href="{{site.linkedin}}"><b>LinkedIn</b></a></div> |
            <div class="inline-block"><a href="{{site.github}}"><b>Github</b></a></div> |
            <div class="inline-block"><a href="{{site.website}}"><b>Technical</b></a></div>
        </div>
    </div>
    <hr>

    <div style="width: 100%;">
        <h5>Technical Skills</h5>
        <div style="width: 50%;float: left;">
            <div>- <b>Code: </b>Python, bash, SQL, powershell, Java, C/C++</div>
            <div>- <b>CI/CD: </b>Github Actions, Azure DevOps, Jenkins, ArgoCD</div>
            <div>- <b>Cloud/IaC: </b>AWS(<a href="https://www.credly.com/badges/7b9973d0-099a-46ba-9962-281fc1aa0bdb">Certified</a>), Azure, Terraform, Packer, Pulumi</div>
        </div>
        <div style="width: 50%;margin-left: 50%;">
            <div>- <b>Configuration: </b>cloud-init, SaltStack, Ansible</div>
            <div>- <b>Container: </b>Docker, Podman, Kubernetes, Rancher</div>
            <div>- <b>Observability: </b>Datadog, Grafana, Loki, Prometheus</div>
        </div>
    </div>
    <hr>

    <div>
        <h5>Experience</h5>
        <div class="space-between bold-text">
            <div>DevOps Engineer</div>
            <div>July 2021 - Present</div>
        </div>
        <div class="space-between">
            <div><b>DataJoint</b> - <span class="italic-text">Provide science operation for neuroscience research.</span></div>
            <div>Houston, TX</div>
        </div>
        <div class="exp-content">
            <ul>
                <li><b>DataJoint Works</b> - <span class="italic-text">A SaaS platform to empower scientists to design and operate data pipelines for their experiments and analysis in a more efficient, scalable, valid, and reproducible way.</span> [<a href="https://datajoint.com">Details</a>]</li>
                <ul>
                    <li>Developed <b>Terraform</b> modules to manage public/private network, database, ephemeral resource lifecycle, security, event-driven automation, budget and usage alert, notification, and monitoring across DataJoint's and customers' <b>AWS</b> accounts</li>
                    <li>Developed <b>CI/CD</b> in <b>Github Actions</b> leveraging <b>spot instances</b> as self-hosted runner for build, test and deployment.</li>
                    <li>Provisioned, configured and maintained managed and self-hosted <b>Kubernetes</b> clusters.</li>
                    <li>Integrated single sign-on, role-based access control, secret manager, and vulnerability scan for <b>security compliance</b>.</li>
                    <li>Introduced <b>OpenTelemetry</b> to the team and integrated observability with <b>CloudWatch</b>, <b>Datadog</b>, <b>Loki</b>, and <b>Grafana</b>.</li>
                    <li>Implemented admin API with <b>FastAPI</b>, <b>SQL</b>, <b>boto3</b>, and <b>Pulumi</b> to enable users to manage compute infrastructure.</li>
                    <li>Architected and implemented ephemeral job scheduler in <b>Python</b> as core component with <b>Packer</b> and <b>Terraform</b>.</li>
                    <li>Extended <b>Jupyterhub</b> with remote kernel on top of the existing architecture to reuse <b>idle</b> compute interactively.</li>
                    <li>Collaborated with the team in an <b>Agile</b> approach using <b>Jira</b>, also used <b>Github Project</b> for open-source projects.</li>
                </ul>
                <li><b>DataJoint Core/Elements</b> - DataJoint Core is an open-source toolkit for defining and operating computational data pipelines. DataJoint Elements is a collection of pre-assembled modules for neuroscience pipelines. [<a href="https://github.com/datajoint">Github</a>]</li>
                <ul>
                    <li>Improved <b>docker</b> build consistency, efficiency and security.</li>
                    <li>Improved and automated Python package <b>releases</b> by conventional commit and semantic versioning.</li>
                    <li>Integrated <b>mkdocs</b> to improve documentation development efficiency and reader experience.</li>
                </ul>
                <li class="italic-text">DataJoint Works, Core, and Elements improve the research efficiency of 10+ neuroscience labs as of this moment. My contribution technically improves DataJoint Works' robustness, flexibility, and scalability, also automates manual toil through internal and external collaboration to improve productivity in both commercial and open-source development.</li>
            </ul>
        </div>
        <div class="space-between bold-text">
            <div>Software Engineer</div>
            <div>May 2019 - July 2021</div>
        </div>
        <div class="space-between">
            <div><b>dataVediK</b> - <span class="italic-text">Optimized oil and gas operations with machine learning.</span></div>
            <div>Houston, TX</div>
        </div>
        <div class="exp-content">
            <ul>
                <li><b>Hyper-converged Data Analysis Platform</b> - <span class="italic-text">A SaaS platform integrating data management, machine learning, and data analytic services for oil and gas.</span> [<a href="https://www.agoraiot.com/marketplace/drillvedik">DrillVedik</a>]</li>
                <ul>
                    <li>Implemented <b>CI/CD</b> pipelines with <b>Azure DevOps</b> and <b>Jenkins</b> for build, test, validation, and deployment.</li>
                    <li>Integrated <b>MLflow</b> as a machine learning operational pipeline to improve model comparison, versioning, and serving.</li>
                    <li>Set up <b>Airflow</b> to automate the data processing pipeline.</li>
                    <li>Developed DrillVedik interactive drilling analytic dashboard with <b>Plotly Dash</b>, <b>Flask</b>, and <b>Redis</b>.</li>
                    <li>Architected and developed the full stack of the prediction task manager web application with <b>HTML</b>, <b>CSS</b>, <b>JavaScript</b>, <b>Flask</b>, <b>Celery</b>, <b>RabbitMQ</b>, <b>gunicorn</b>, and <b>nginx</b>.</li>
                    <li>Analyzed drilling pump operation data and trained multiple machine learning models to <b>classify</b> drilling status.</li>
                    <li>Researched and applied feature engineering on drilling data, and trained a <b>regression</b> model for drilling prediction.</li>
                </ul>
                <li class="italic-text">Although this was an MVP project, I learned and practiced a variety of hands-on skills from software development and deployment, machine learning to cloud computing. It also inspired me about the importance of DevOps through collaboration.</li>
            </ul>
        </div>
    </div>
    <hr>

    <div>
        <h5>Education</h5>
        <div class="space-between">
            <div>Southern Methodist University, <i>Master's of Computer Science</i></div>
            <div>Dallas, TX | Aug 2017 - May 2019</div>
        </div>
        <div class="space-between italic-text">
            <div></div>
            <div></div>
        </div>
        <div class="space-between">
            <div>Qingdao University, <i>Bachelor's of Software Engineering</i></div>
            <div>Qingdao, China | Aug 2013 - May 2017</div>
        </div>
        <div class="space-between italic-text">
            <div></div>
            <div></div>
        </div>
    </div>
</div>